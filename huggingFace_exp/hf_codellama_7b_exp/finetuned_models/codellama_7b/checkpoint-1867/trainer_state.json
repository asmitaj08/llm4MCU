{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1867,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01339405304045004,
      "grad_norm": 1.4905049800872803,
      "learning_rate": 4.9785637727759915e-05,
      "loss": 3.9274,
      "step": 25
    },
    {
      "epoch": 0.02678810608090008,
      "grad_norm": 1.3330000638961792,
      "learning_rate": 4.9562343694176496e-05,
      "loss": 2.4115,
      "step": 50
    },
    {
      "epoch": 0.04018215912135012,
      "grad_norm": 0.8940703868865967,
      "learning_rate": 4.933904966059307e-05,
      "loss": 1.1267,
      "step": 75
    },
    {
      "epoch": 0.05357621216180016,
      "grad_norm": 0.5991283655166626,
      "learning_rate": 4.9115755627009646e-05,
      "loss": 0.6968,
      "step": 100
    },
    {
      "epoch": 0.0669702652022502,
      "grad_norm": 0.715957760810852,
      "learning_rate": 4.889246159342623e-05,
      "loss": 0.6106,
      "step": 125
    },
    {
      "epoch": 0.08036431824270024,
      "grad_norm": 0.6335316896438599,
      "learning_rate": 4.86691675598428e-05,
      "loss": 0.5717,
      "step": 150
    },
    {
      "epoch": 0.09375837128315029,
      "grad_norm": 0.5877699255943298,
      "learning_rate": 4.8445873526259384e-05,
      "loss": 0.5276,
      "step": 175
    },
    {
      "epoch": 0.10715242432360032,
      "grad_norm": 0.5803064703941345,
      "learning_rate": 4.822257949267596e-05,
      "loss": 0.5287,
      "step": 200
    },
    {
      "epoch": 0.12054647736405036,
      "grad_norm": 0.6183506846427917,
      "learning_rate": 4.7999285459092534e-05,
      "loss": 0.4992,
      "step": 225
    },
    {
      "epoch": 0.1339405304045004,
      "grad_norm": 0.6671416163444519,
      "learning_rate": 4.7775991425509115e-05,
      "loss": 0.484,
      "step": 250
    },
    {
      "epoch": 0.14733458344495043,
      "grad_norm": 0.6388781070709229,
      "learning_rate": 4.755269739192569e-05,
      "loss": 0.4943,
      "step": 275
    },
    {
      "epoch": 0.16072863648540048,
      "grad_norm": 0.7327852249145508,
      "learning_rate": 4.7329403358342265e-05,
      "loss": 0.4725,
      "step": 300
    },
    {
      "epoch": 0.17412268952585053,
      "grad_norm": 0.6768126487731934,
      "learning_rate": 4.7106109324758847e-05,
      "loss": 0.4496,
      "step": 325
    },
    {
      "epoch": 0.18751674256630058,
      "grad_norm": 0.6083640456199646,
      "learning_rate": 4.688281529117543e-05,
      "loss": 0.4553,
      "step": 350
    },
    {
      "epoch": 0.2009107956067506,
      "grad_norm": 0.7741093039512634,
      "learning_rate": 4.6659521257591996e-05,
      "loss": 0.4281,
      "step": 375
    },
    {
      "epoch": 0.21430484864720065,
      "grad_norm": 0.70806884765625,
      "learning_rate": 4.643622722400858e-05,
      "loss": 0.4264,
      "step": 400
    },
    {
      "epoch": 0.2276989016876507,
      "grad_norm": 0.7266253232955933,
      "learning_rate": 4.621293319042516e-05,
      "loss": 0.4146,
      "step": 425
    },
    {
      "epoch": 0.24109295472810072,
      "grad_norm": 0.7420895099639893,
      "learning_rate": 4.598963915684173e-05,
      "loss": 0.3735,
      "step": 450
    },
    {
      "epoch": 0.25448700776855077,
      "grad_norm": 0.861459493637085,
      "learning_rate": 4.576634512325831e-05,
      "loss": 0.3767,
      "step": 475
    },
    {
      "epoch": 0.2678810608090008,
      "grad_norm": 0.7784489989280701,
      "learning_rate": 4.554305108967489e-05,
      "loss": 0.3641,
      "step": 500
    },
    {
      "epoch": 0.28127511384945086,
      "grad_norm": 0.7700006365776062,
      "learning_rate": 4.531975705609146e-05,
      "loss": 0.3471,
      "step": 525
    },
    {
      "epoch": 0.29466916688990086,
      "grad_norm": 0.8791667819023132,
      "learning_rate": 4.509646302250804e-05,
      "loss": 0.3417,
      "step": 550
    },
    {
      "epoch": 0.3080632199303509,
      "grad_norm": 0.760023295879364,
      "learning_rate": 4.487316898892462e-05,
      "loss": 0.3512,
      "step": 575
    },
    {
      "epoch": 0.32145727297080096,
      "grad_norm": 0.9218626022338867,
      "learning_rate": 4.46498749553412e-05,
      "loss": 0.3266,
      "step": 600
    },
    {
      "epoch": 0.334851326011251,
      "grad_norm": 1.0537647008895874,
      "learning_rate": 4.442658092175777e-05,
      "loss": 0.3355,
      "step": 625
    },
    {
      "epoch": 0.34824537905170105,
      "grad_norm": 1.1164579391479492,
      "learning_rate": 4.420328688817435e-05,
      "loss": 0.3266,
      "step": 650
    },
    {
      "epoch": 0.3616394320921511,
      "grad_norm": 1.0582681894302368,
      "learning_rate": 4.397999285459093e-05,
      "loss": 0.3176,
      "step": 675
    },
    {
      "epoch": 0.37503348513260115,
      "grad_norm": 0.8431617021560669,
      "learning_rate": 4.37566988210075e-05,
      "loss": 0.3157,
      "step": 700
    },
    {
      "epoch": 0.38842753817305115,
      "grad_norm": 1.1432774066925049,
      "learning_rate": 4.3533404787424084e-05,
      "loss": 0.3207,
      "step": 725
    },
    {
      "epoch": 0.4018215912135012,
      "grad_norm": 0.976091742515564,
      "learning_rate": 4.331011075384066e-05,
      "loss": 0.3225,
      "step": 750
    },
    {
      "epoch": 0.41521564425395124,
      "grad_norm": 1.0849816799163818,
      "learning_rate": 4.308681672025724e-05,
      "loss": 0.3097,
      "step": 775
    },
    {
      "epoch": 0.4286096972944013,
      "grad_norm": 0.7388479709625244,
      "learning_rate": 4.2863522686673816e-05,
      "loss": 0.3111,
      "step": 800
    },
    {
      "epoch": 0.44200375033485134,
      "grad_norm": 0.940429151058197,
      "learning_rate": 4.264022865309039e-05,
      "loss": 0.2963,
      "step": 825
    },
    {
      "epoch": 0.4553978033753014,
      "grad_norm": 0.9493727087974548,
      "learning_rate": 4.241693461950697e-05,
      "loss": 0.2861,
      "step": 850
    },
    {
      "epoch": 0.4687918564157514,
      "grad_norm": 1.0036063194274902,
      "learning_rate": 4.219364058592355e-05,
      "loss": 0.3035,
      "step": 875
    },
    {
      "epoch": 0.48218590945620143,
      "grad_norm": 0.9269081950187683,
      "learning_rate": 4.197034655234012e-05,
      "loss": 0.3111,
      "step": 900
    },
    {
      "epoch": 0.4955799624966515,
      "grad_norm": 0.8546565771102905,
      "learning_rate": 4.17470525187567e-05,
      "loss": 0.2973,
      "step": 925
    },
    {
      "epoch": 0.5089740155371015,
      "grad_norm": 1.0723605155944824,
      "learning_rate": 4.152375848517328e-05,
      "loss": 0.2851,
      "step": 950
    },
    {
      "epoch": 0.5223680685775516,
      "grad_norm": 0.9260022044181824,
      "learning_rate": 4.130046445158985e-05,
      "loss": 0.2861,
      "step": 975
    },
    {
      "epoch": 0.5357621216180016,
      "grad_norm": 0.840735673904419,
      "learning_rate": 4.1077170418006434e-05,
      "loss": 0.3037,
      "step": 1000
    },
    {
      "epoch": 0.5491561746584517,
      "grad_norm": 0.9994663000106812,
      "learning_rate": 4.085387638442301e-05,
      "loss": 0.2869,
      "step": 1025
    },
    {
      "epoch": 0.5625502276989017,
      "grad_norm": 0.9432574510574341,
      "learning_rate": 4.0630582350839584e-05,
      "loss": 0.294,
      "step": 1050
    },
    {
      "epoch": 0.5759442807393518,
      "grad_norm": 0.8182719945907593,
      "learning_rate": 4.0407288317256166e-05,
      "loss": 0.2738,
      "step": 1075
    },
    {
      "epoch": 0.5893383337798017,
      "grad_norm": 0.9875134825706482,
      "learning_rate": 4.018399428367274e-05,
      "loss": 0.2887,
      "step": 1100
    },
    {
      "epoch": 0.6027323868202518,
      "grad_norm": 0.9147534370422363,
      "learning_rate": 3.9960700250089315e-05,
      "loss": 0.2963,
      "step": 1125
    },
    {
      "epoch": 0.6161264398607018,
      "grad_norm": 1.1223948001861572,
      "learning_rate": 3.97374062165059e-05,
      "loss": 0.2849,
      "step": 1150
    },
    {
      "epoch": 0.6295204929011519,
      "grad_norm": 0.9061877727508545,
      "learning_rate": 3.951411218292247e-05,
      "loss": 0.2728,
      "step": 1175
    },
    {
      "epoch": 0.6429145459416019,
      "grad_norm": 1.0950931310653687,
      "learning_rate": 3.929081814933905e-05,
      "loss": 0.2778,
      "step": 1200
    },
    {
      "epoch": 0.656308598982052,
      "grad_norm": 1.1293002367019653,
      "learning_rate": 3.906752411575563e-05,
      "loss": 0.2745,
      "step": 1225
    },
    {
      "epoch": 0.669702652022502,
      "grad_norm": 0.9998095631599426,
      "learning_rate": 3.88442300821722e-05,
      "loss": 0.2782,
      "step": 1250
    },
    {
      "epoch": 0.6830967050629521,
      "grad_norm": 0.9303356409072876,
      "learning_rate": 3.8620936048588785e-05,
      "loss": 0.2718,
      "step": 1275
    },
    {
      "epoch": 0.6964907581034021,
      "grad_norm": 0.9688259959220886,
      "learning_rate": 3.839764201500536e-05,
      "loss": 0.2765,
      "step": 1300
    },
    {
      "epoch": 0.7098848111438522,
      "grad_norm": 1.1353448629379272,
      "learning_rate": 3.8174347981421934e-05,
      "loss": 0.2605,
      "step": 1325
    },
    {
      "epoch": 0.7232788641843022,
      "grad_norm": 1.2511919736862183,
      "learning_rate": 3.7951053947838516e-05,
      "loss": 0.2676,
      "step": 1350
    },
    {
      "epoch": 0.7366729172247523,
      "grad_norm": 1.1914199590682983,
      "learning_rate": 3.77277599142551e-05,
      "loss": 0.2623,
      "step": 1375
    },
    {
      "epoch": 0.7500669702652023,
      "grad_norm": 0.9698443412780762,
      "learning_rate": 3.7504465880671665e-05,
      "loss": 0.2596,
      "step": 1400
    },
    {
      "epoch": 0.7634610233056522,
      "grad_norm": 1.2940926551818848,
      "learning_rate": 3.728117184708825e-05,
      "loss": 0.2669,
      "step": 1425
    },
    {
      "epoch": 0.7768550763461023,
      "grad_norm": 0.9568777680397034,
      "learning_rate": 3.705787781350483e-05,
      "loss": 0.2649,
      "step": 1450
    },
    {
      "epoch": 0.7902491293865523,
      "grad_norm": 1.110059380531311,
      "learning_rate": 3.68345837799214e-05,
      "loss": 0.2534,
      "step": 1475
    },
    {
      "epoch": 0.8036431824270024,
      "grad_norm": 1.2022334337234497,
      "learning_rate": 3.661128974633798e-05,
      "loss": 0.2578,
      "step": 1500
    },
    {
      "epoch": 0.8170372354674524,
      "grad_norm": 0.9775505661964417,
      "learning_rate": 3.638799571275456e-05,
      "loss": 0.2642,
      "step": 1525
    },
    {
      "epoch": 0.8304312885079025,
      "grad_norm": 1.0487926006317139,
      "learning_rate": 3.6164701679171135e-05,
      "loss": 0.2632,
      "step": 1550
    },
    {
      "epoch": 0.8438253415483525,
      "grad_norm": 1.1899590492248535,
      "learning_rate": 3.594140764558771e-05,
      "loss": 0.2785,
      "step": 1575
    },
    {
      "epoch": 0.8572193945888026,
      "grad_norm": 1.1265990734100342,
      "learning_rate": 3.571811361200429e-05,
      "loss": 0.2662,
      "step": 1600
    },
    {
      "epoch": 0.8706134476292526,
      "grad_norm": 1.0818371772766113,
      "learning_rate": 3.5494819578420866e-05,
      "loss": 0.2591,
      "step": 1625
    },
    {
      "epoch": 0.8840075006697027,
      "grad_norm": 1.0069172382354736,
      "learning_rate": 3.527152554483744e-05,
      "loss": 0.2543,
      "step": 1650
    },
    {
      "epoch": 0.8974015537101527,
      "grad_norm": 1.0341870784759521,
      "learning_rate": 3.504823151125402e-05,
      "loss": 0.2692,
      "step": 1675
    },
    {
      "epoch": 0.9107956067506028,
      "grad_norm": 1.3508957624435425,
      "learning_rate": 3.48249374776706e-05,
      "loss": 0.2548,
      "step": 1700
    },
    {
      "epoch": 0.9241896597910527,
      "grad_norm": 1.0272955894470215,
      "learning_rate": 3.460164344408718e-05,
      "loss": 0.2523,
      "step": 1725
    },
    {
      "epoch": 0.9375837128315028,
      "grad_norm": 1.1992541551589966,
      "learning_rate": 3.4378349410503754e-05,
      "loss": 0.2543,
      "step": 1750
    },
    {
      "epoch": 0.9509777658719528,
      "grad_norm": 1.1596901416778564,
      "learning_rate": 3.415505537692033e-05,
      "loss": 0.2523,
      "step": 1775
    },
    {
      "epoch": 0.9643718189124029,
      "grad_norm": 1.0910412073135376,
      "learning_rate": 3.393176134333691e-05,
      "loss": 0.2479,
      "step": 1800
    },
    {
      "epoch": 0.9777658719528529,
      "grad_norm": 0.9226016998291016,
      "learning_rate": 3.3708467309753485e-05,
      "loss": 0.2466,
      "step": 1825
    },
    {
      "epoch": 0.991159924993303,
      "grad_norm": 0.899502694606781,
      "learning_rate": 3.348517327617006e-05,
      "loss": 0.247,
      "step": 1850
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2487439066171646,
      "eval_runtime": 542.4472,
      "eval_samples_per_second": 6.664,
      "eval_steps_per_second": 3.333,
      "step": 1867
    }
  ],
  "logging_steps": 25,
  "max_steps": 5598,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.065630844750397e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
