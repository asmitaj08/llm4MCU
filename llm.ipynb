{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Path to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"unstructured[all-docs]\" chromadb pydantic lxml tiktoken langchain langchain-community langchain-openai langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.prompts import PromptTemplate\n",
    "import uuid\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.schema.document import Document\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = './nRF52840_PS_v1.8.pdf'\n",
    "uart_pdf_path='./uart.pdf'\n",
    "image_path = \"./images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest PDF \n",
    "\n",
    "Split the pdf into text chunks, save any table and images as images and store them into a separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_elements = partition_pdf(\n",
    "    pdf_path,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    extract_image_block_types=['Table', 'Image'],\n",
    "    extract_image_block_output_dir='./images',\n",
    "    max_characters=3000,\n",
    "    new_after_n_chars=2800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=image_path\n",
    "    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_elements(raw_pdf_elements):\n",
    "    text_elements = []\n",
    "    table_elements = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if 'CompositeElement' in str(type(element)):\n",
    "            text_elements.append(str(element))\n",
    "        elif 'Table' in str(type(element)):\n",
    "            table_elements.append(str(element))\n",
    "    return text_elements, table_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2711/2711 [00:00<00:00, 487325.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n",
      "1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract tables and texts\n",
    "texts, tables = categorize_elements(pdf_elements)\n",
    "\n",
    "# length of text elem\n",
    "print(len(texts))\n",
    "\n",
    "# length of table elem\n",
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate summaries for the text blocks and table/images. \n",
    "\n",
    "These descriptions help to match a query better, so that we don't have to deal with the spaces and formatting from the direct extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0, max_tokens=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries of text elements\n",
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a concise summary of the table or text that is well-optimized for retrieval. \\\n",
    "    Don't use Markdown, just plain text output. Table \\\n",
    "    or text: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Text summary chain\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "# Get text & table summaries\n",
    "text_summaries, table_summaries = generate_text_summaries(texts[0:19], tables, summarize_texts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "# encode image\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Getting the base64 string\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_summarize(img_base64, prompt):\n",
    "    \"\"\"Make image summary\"\"\"\n",
    "    msg = model.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_summaries(path):\n",
    "    \"\"\"\n",
    "    Generate summaries and base64 encoded strings for images\n",
    "    path: Path to list of .jpg files extracted by Unstructured\n",
    "    \"\"\"\n",
    "    # Store base64 encoded images\n",
    "    img_base64_list = []\n",
    "\n",
    "    # Store image summaries\n",
    "    image_summaries = []\n",
    "\n",
    "    # Prompt\n",
    "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw image. \\\n",
    "    Include all the values in each image, including extracting all the text. \\\n",
    "    Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
    "\n",
    "    # Apply to images\n",
    "    for img_file in sorted(os.listdir(path)):\n",
    "        if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "            base64_image = encode_image(img_path)\n",
    "            img_base64_list.append(base64_image)\n",
    "            image_summaries.append(image_summarize(base64_image, prompt))\n",
    "\n",
    "    return img_base64_list, image_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./images\"\n",
    "# Image summaries\n",
    "img_base64_list, image_summaries = generate_img_summaries(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a vector database to store summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_vector_retriever(vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images):\n",
    "    \"\"\"\n",
    "    Create retriever that indexes summaries, but returns raw images or texts\n",
    "    \"\"\"\n",
    "    # Initialize the storage layer\n",
    "    store = InMemoryStore()\n",
    "    id_key = \"doc_id\"\n",
    "\n",
    "    # Create the multi-vector retriever\n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=store,\n",
    "        id_key=id_key,\n",
    "    )\n",
    "    \n",
    "    # Helper function to add documents to the vectorstore and docstore\n",
    "    def add_documents(retriever, doc_summaries, doc_contents):\n",
    "        doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "        summary_docs = [\n",
    "            Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "            for i, s in enumerate(doc_summaries)\n",
    "        ]\n",
    "        retriever.vectorstore.add_documents(summary_docs)\n",
    "        retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "    # Add texts, tables, and images\n",
    "    # Check that text_summaries is not empty before adding\n",
    "    if text_summaries:\n",
    "        add_documents(retriever, text_summaries, texts)\n",
    "    # Check that table_summaries is not empty before adding\n",
    "    if table_summaries:\n",
    "        add_documents(retriever, table_summaries, tables)\n",
    "    # Check that image_summaries is not empty before adding\n",
    "    if image_summaries:\n",
    "        add_documents(retriever, image_summaries, images)\n",
    "\n",
    "    return retriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vectorstore to use to index the summaries\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"mm_rag\",\n",
    "    embedding_function = OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\")),\n",
    "    persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever_multi_vector_img = create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    text_summaries,\n",
    "    texts,\n",
    "    table_summaries,\n",
    "    tables,\n",
    "    image_summaries,\n",
    "    img_base64_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"Disply base64 encoded string as image\"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "def looks_like_base64(sb):\n",
    "    \"\"\"Check if the string looks like base64\"\"\"\n",
    "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n",
    "\n",
    "\n",
    "def is_image_data(b64data):\n",
    "    \"\"\"\n",
    "    Check if the base64 data is an image by looking at the start of the data\n",
    "    \"\"\"\n",
    "    image_signatures = {\n",
    "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
    "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
    "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
    "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
    "    }\n",
    "    try:\n",
    "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
    "        for sig, format in image_signatures.items():\n",
    "            if header.startswith(sig):\n",
    "                return True\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def resize_base64_image(base64_string, size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Resize an image encoded as a Base64 string\n",
    "    \"\"\"\n",
    "    # Decode the Base64 string\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(io.BytesIO(img_data))\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = img.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to a bytes buffer\n",
    "    buffered = io.BytesIO()\n",
    "    resized_img.save(buffered, format=img.format)\n",
    "\n",
    "    # Encode the resized image to Base64\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def split_image_text_types(docs):\n",
    "    \"\"\"\n",
    "    Split base64-encoded images and texts\n",
    "    \"\"\"\n",
    "    b64_images = []\n",
    "    texts = []\n",
    "    for doc in docs:\n",
    "        # Check if the document is of type Document and extract page_content if so\n",
    "        if isinstance(doc, Document):\n",
    "            doc = doc.page_content\n",
    "        if looks_like_base64(doc) and is_image_data(doc):\n",
    "            doc = resize_base64_image(doc, size=(1300, 600))\n",
    "            b64_images.append(doc)\n",
    "        else:\n",
    "            texts.append(doc)\n",
    "    if len(b64_images) > 0:\n",
    "        return {\"images\": b64_images[:1], \"texts\": []}\n",
    "    return {\"images\": b64_images, \"texts\": texts}\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare RAG pipeline  \n",
    "user can ask question and the query will search for relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_prompt_func(data_dict):\n",
    "    \"\"\"\n",
    "    Join the context into a single string\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Adding the text for analysis\n",
    "    text_message = {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": (\n",
    "            \"You are an AI scientist tasking with providing factual answers from a datasheet of a System-on-Chip (SoC) \\n\"\n",
    "            \"Use this information to provide answers related to the user question. \\n\"\n",
    "            f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
    "        ),\n",
    "    }\n",
    "    messages.append(text_message)\n",
    "    # Adding image(s) to the messages if present\n",
    "    if data_dict[\"context\"][\"images\"]:\n",
    "        for image in data_dict[\"context\"][\"images\"]:\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
    "            }\n",
    "            messages.append(image_message)\n",
    "    return [HumanMessage(content=messages)]\n",
    "\n",
    "def multi_modal_rag_chain(retriever):\n",
    "    \"\"\"\n",
    "    Multi-modal RAG chain\n",
    "    \"\"\"\n",
    "\n",
    "    # RAG pipeline\n",
    "    chain = (\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(split_image_text_types),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | RunnableLambda(img_prompt_func)\n",
    "        | model  # MM_LLM\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'images': [],\n",
       " 'texts': ['Bit number ID Reset 0x00000000 ID AccessField Value ID A W TASKS_STARTTX Trigger 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Value Description Start UART transmitter 1 Trigger task',\n",
       "  'Bit number ID Reset 0x00000000 ID AccessField Value ID A W TASKS_STARTRX Trigger 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 A 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Value Description Start UART receiver 1 Trigger task',\n",
       "  'Symbol Description Min. Typ. Max. Units fUART Baud rate for UART41. 1000 kbps tUART,CTSH CTS high time 1 µs tUART,START Time from STARTRX/STARTTX task to transmission started 1 µs',\n",
       "  'Bit number ID Reset 0x00000000 ID AccessField Value ID A W TASKS_STARTRX Trigger 31 30 29 28 27 26 25 24 23 22 21 20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Value Description Start UART receiver 1 Trigger task']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"What is the starting address of UART?\"\"\"\n",
    "docs = retriever_multi_vector_img.get_relevant_documents(query, limit=1)\n",
    "split_image_text_types(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_bot(query):\n",
    "    # docs = retriever_multi_vector_img.get_relevant_documents(query, limit=10)\n",
    "    # print(split_image_text_types(docs))\n",
    "    return chain_multimodal_rag.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base address of the UART is 0x40002000.\n"
     ]
    }
   ],
   "source": [
    "response = ask_bot(\"What is the base address of UART\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The UART has the following registers:\n",
      "\n",
      "1. **TASKS_STARTRX**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x000\n",
      "\n",
      "2. **TASKS_STOPRX**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x004\n",
      "\n",
      "3. **TASKS_STARTTX**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x008\n",
      "\n",
      "4. **TASKS_STOPTX**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x00C\n",
      "\n",
      "5. **TASKS_SUSPEND**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x01C\n",
      "\n",
      "6. **EVENTS_CTS**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x100\n",
      "\n",
      "7. **EVENTS_NCTS**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x104\n",
      "\n",
      "8. **EVENTS_RXDRDY**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x108\n",
      "\n",
      "9. **EVENTS_TXDRDY**\n",
      "   - Size: Not specified\n",
      "   - Address Offset: 0x11C\n",
      "\n",
      "10. **EVENTS_ERROR**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x124\n",
      "\n",
      "11. **EVENTS_RXTO**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x144\n",
      "\n",
      "12. **SHORTS**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x200\n",
      "\n",
      "13. **INTENSET**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x304\n",
      "\n",
      "14. **INTENCLR**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x308\n",
      "\n",
      "15. **ERRORSRC**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x480\n",
      "\n",
      "16. **ENABLE**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x500\n",
      "\n",
      "17. **PSEL.RTS**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x508\n",
      "\n",
      "18. **PSEL.TXD**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x50C\n",
      "\n",
      "19. **PSEL.CTS**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x510\n",
      "\n",
      "20. **PSEL.RXD**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x514\n",
      "\n",
      "21. **RXD**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x518\n",
      "\n",
      "22. **TXD**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x51C\n",
      "\n",
      "23. **BAUDRATE**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x524\n",
      "\n",
      "24. **CONFIG**\n",
      "    - Size: Not specified\n",
      "    - Address Offset: 0x56C\n",
      "\n",
      "The datasheet does not specify the size of each register.\n"
     ]
    }
   ],
   "source": [
    "print(ask_bot(\"How many registers does UART have? List their name, size, and address offset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"list all peripherals and their base address, and description\"\n",
    "docs = retriever_multi_vector_img.get_relevant_documents(query, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of peripherals, their base addresses, and descriptions:\n",
      "\n",
      "1. **SWI5**\n",
      "   - Base Address: 0x40019000\n",
      "   - Description: Software interrupt 5\n",
      "\n",
      "2. **TIMER3**\n",
      "   - Base Address: 0x4001A000\n",
      "   - Description: Timer 3\n",
      "\n",
      "3. **TIMER4**\n",
      "   - Base Address: 0x4001B000\n",
      "   - Description: Timer 4\n",
      "\n",
      "4. **PWM0**\n",
      "   - Base Address: 0x4001C000\n",
      "   - Description: Pulse width modulation unit 0\n",
      "\n",
      "5. **PDM**\n",
      "   - Base Address: 0x4001D000\n",
      "   - Description: Pulse Density modulation (digital microphone) interface\n",
      "\n",
      "6. **ACL**\n",
      "   - Base Address: 0x4001E000\n",
      "   - Description: Access control lists\n",
      "\n",
      "7. **NVMC**\n",
      "   - Base Address: 0x4001E000\n",
      "   - Description: Non-volatile memory controller\n",
      "\n",
      "8. **PPI**\n",
      "   - Base Address: 0x4001F000\n",
      "   - Description: Programmable peripheral interconnect\n",
      "\n",
      "9. **MWU**\n",
      "   - Base Address: 0x40020000\n",
      "   - Description: Memory watch unit\n",
      "\n",
      "10. **PWM1**\n",
      "    - Base Address: 0x40021000\n",
      "    - Description: Pulse width modulation unit 1\n",
      "\n",
      "11. **PWM2**\n",
      "    - Base Address: 0x40022000\n",
      "    - Description: Pulse width modulation unit 2\n",
      "\n",
      "12. **SPI2**\n",
      "    - Base Address: 0x40023000\n",
      "    - Description: SPI master 2\n",
      "\n",
      "13. **SPIM2**\n",
      "    - Base Address: 0x40023000\n",
      "    - Description: SPI master 2 (Deprecated)\n",
      "\n",
      "14. **SPIS2**\n",
      "    - Base Address: 0x40024000\n",
      "    - Description: SPI slave 2\n",
      "\n",
      "15. **RTC2**\n",
      "    - Base Address: 0x40024000\n",
      "    - Description: Real-time counter 2\n",
      "\n",
      "16. **I2S**\n",
      "    - Base Address: 0x40025000\n",
      "    - Description: Inter-IC sound interface\n",
      "\n",
      "17. **FPU**\n",
      "    - Base Address: 0x40026000\n",
      "    - Description: FPU interrupt\n",
      "\n",
      "18. **USBD**\n",
      "    - Base Address: 0x40027000\n",
      "    - Description: Universal serial bus device\n",
      "\n",
      "19. **UARTE1**\n",
      "    - Base Address: 0x40028000\n",
      "    - Description: Universal asynchronous receiver/transmitter with EasyDMA, unit 1\n",
      "\n",
      "20. **QSPI**\n",
      "    - Base Address: 0x40029000\n",
      "    - Description: External memory interface\n",
      "\n",
      "21. **CC_HOST_RGF**\n",
      "    - Base Address: 0x5002A000\n",
      "    - Description: Host platform interface\n",
      "\n",
      "22. **CRYPTOCELL**\n",
      "    - Base Address: 0x5002A000\n",
      "    - Description: CryptoCell subsystem control interface\n",
      "\n",
      "23. **PWM3**\n",
      "    - Base Address: 0x4002D000\n",
      "    - Description: Pulse width modulation unit 3\n",
      "\n",
      "24. **SPIM3**\n",
      "    - Base Address: 0x4002F000\n",
      "    - Description: SPI master 3\n",
      "\n",
      "25. **FICR**\n",
      "    - Base Address: N/A\n",
      "    - Description: Factory information configuration\n",
      "\n",
      "26. **UICR**\n",
      "    - Base Address: N/A\n",
      "    - Description: User information configuration\n"
     ]
    }
   ],
   "source": [
    "print(ask_bot(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory map of the System-on-Chip (SoC) is organized into distinct regions, each serving a specific purpose. Here's a breakdown of the system address map:\n",
      "\n",
      "1. **Code (0x00000000 - 0x1FFFFFFF):**\n",
      "   - This region is designated for executable code. It typically contains the firmware or software that runs on the SoC.\n",
      "\n",
      "2. **XIP (Execute In Place) (0x20000000 - 0x3FFFFFFF):**\n",
      "   - This area is used for executing code directly from external flash memory without copying it to RAM. The XIP region in the system address map corresponds to a section in the external flash memory.\n",
      "\n",
      "3. **SRAM (0x40000000 - 0x5FFFFFFF):**\n",
      "   - This section is allocated for static RAM, which is used for data storage and manipulation during program execution.\n",
      "\n",
      "4. **Peripheral (0x40000000 - 0x5FFFFFFF):**\n",
      "   - This region is used for memory-mapped peripheral devices. It allows the CPU to interact with hardware components like timers, UARTs, and other I/O devices.\n",
      "\n",
      "5. **RAM (0x60000000 and above):**\n",
      "   - This area is for dynamic RAM, providing additional memory space for data storage and processing.\n",
      "\n",
      "**External Flash:**\n",
      "- The external flash memory contains a section for XIP, allowing the SoC to execute code directly from this memory. The XIPOFFSET indicates the starting point of the XIP section within the external flash.\n",
      "\n",
      "This memory map allows efficient use of resources by organizing memory into regions optimized for specific tasks, such as code execution, data storage, and peripheral interaction.\n"
     ]
    }
   ],
   "source": [
    "print(ask_bot(\"Explain the memory map, describe the system address map and the address map.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the peripherals listed in the datasheet:\n",
      "\n",
      "1. **Peripheral:** PWM\n",
      "   - **Base Address:** 0x4001C000\n",
      "   - **Instance:** PWM0\n",
      "   - **Description:** Pulse width modulation unit 0\n",
      "\n",
      "2. **Peripheral:** PWM\n",
      "   - **Base Address:** 0x40021000\n",
      "   - **Instance:** PWM1\n",
      "   - **Description:** Pulse width modulation unit 1\n",
      "\n",
      "3. **Peripheral:** PWM\n",
      "   - **Base Address:** 0x40022000\n",
      "   - **Instance:** PWM2\n",
      "   - **Description:** Pulse width modulation unit 2\n",
      "\n",
      "4. **Peripheral:** PWM\n",
      "   - **Base Address:** 0x4002D000\n",
      "   - **Instance:** PWM3\n",
      "   - **Description:** Pulse width modulation unit 3\n"
     ]
    }
   ],
   "source": [
    "print(ask_bot(\"List all the peripherals, their base address, instance, and description.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
