{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 3734,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01339405304045004,
      "grad_norm": 1.4905049800872803,
      "learning_rate": 4.9785637727759915e-05,
      "loss": 3.9274,
      "step": 25
    },
    {
      "epoch": 0.02678810608090008,
      "grad_norm": 1.3330000638961792,
      "learning_rate": 4.9562343694176496e-05,
      "loss": 2.4115,
      "step": 50
    },
    {
      "epoch": 0.04018215912135012,
      "grad_norm": 0.8940703868865967,
      "learning_rate": 4.933904966059307e-05,
      "loss": 1.1267,
      "step": 75
    },
    {
      "epoch": 0.05357621216180016,
      "grad_norm": 0.5991283655166626,
      "learning_rate": 4.9115755627009646e-05,
      "loss": 0.6968,
      "step": 100
    },
    {
      "epoch": 0.0669702652022502,
      "grad_norm": 0.715957760810852,
      "learning_rate": 4.889246159342623e-05,
      "loss": 0.6106,
      "step": 125
    },
    {
      "epoch": 0.08036431824270024,
      "grad_norm": 0.6335316896438599,
      "learning_rate": 4.86691675598428e-05,
      "loss": 0.5717,
      "step": 150
    },
    {
      "epoch": 0.09375837128315029,
      "grad_norm": 0.5877699255943298,
      "learning_rate": 4.8445873526259384e-05,
      "loss": 0.5276,
      "step": 175
    },
    {
      "epoch": 0.10715242432360032,
      "grad_norm": 0.5803064703941345,
      "learning_rate": 4.822257949267596e-05,
      "loss": 0.5287,
      "step": 200
    },
    {
      "epoch": 0.12054647736405036,
      "grad_norm": 0.6183506846427917,
      "learning_rate": 4.7999285459092534e-05,
      "loss": 0.4992,
      "step": 225
    },
    {
      "epoch": 0.1339405304045004,
      "grad_norm": 0.6671416163444519,
      "learning_rate": 4.7775991425509115e-05,
      "loss": 0.484,
      "step": 250
    },
    {
      "epoch": 0.14733458344495043,
      "grad_norm": 0.6388781070709229,
      "learning_rate": 4.755269739192569e-05,
      "loss": 0.4943,
      "step": 275
    },
    {
      "epoch": 0.16072863648540048,
      "grad_norm": 0.7327852249145508,
      "learning_rate": 4.7329403358342265e-05,
      "loss": 0.4725,
      "step": 300
    },
    {
      "epoch": 0.17412268952585053,
      "grad_norm": 0.6768126487731934,
      "learning_rate": 4.7106109324758847e-05,
      "loss": 0.4496,
      "step": 325
    },
    {
      "epoch": 0.18751674256630058,
      "grad_norm": 0.6083640456199646,
      "learning_rate": 4.688281529117543e-05,
      "loss": 0.4553,
      "step": 350
    },
    {
      "epoch": 0.2009107956067506,
      "grad_norm": 0.7741093039512634,
      "learning_rate": 4.6659521257591996e-05,
      "loss": 0.4281,
      "step": 375
    },
    {
      "epoch": 0.21430484864720065,
      "grad_norm": 0.70806884765625,
      "learning_rate": 4.643622722400858e-05,
      "loss": 0.4264,
      "step": 400
    },
    {
      "epoch": 0.2276989016876507,
      "grad_norm": 0.7266253232955933,
      "learning_rate": 4.621293319042516e-05,
      "loss": 0.4146,
      "step": 425
    },
    {
      "epoch": 0.24109295472810072,
      "grad_norm": 0.7420895099639893,
      "learning_rate": 4.598963915684173e-05,
      "loss": 0.3735,
      "step": 450
    },
    {
      "epoch": 0.25448700776855077,
      "grad_norm": 0.861459493637085,
      "learning_rate": 4.576634512325831e-05,
      "loss": 0.3767,
      "step": 475
    },
    {
      "epoch": 0.2678810608090008,
      "grad_norm": 0.7784489989280701,
      "learning_rate": 4.554305108967489e-05,
      "loss": 0.3641,
      "step": 500
    },
    {
      "epoch": 0.28127511384945086,
      "grad_norm": 0.7700006365776062,
      "learning_rate": 4.531975705609146e-05,
      "loss": 0.3471,
      "step": 525
    },
    {
      "epoch": 0.29466916688990086,
      "grad_norm": 0.8791667819023132,
      "learning_rate": 4.509646302250804e-05,
      "loss": 0.3417,
      "step": 550
    },
    {
      "epoch": 0.3080632199303509,
      "grad_norm": 0.760023295879364,
      "learning_rate": 4.487316898892462e-05,
      "loss": 0.3512,
      "step": 575
    },
    {
      "epoch": 0.32145727297080096,
      "grad_norm": 0.9218626022338867,
      "learning_rate": 4.46498749553412e-05,
      "loss": 0.3266,
      "step": 600
    },
    {
      "epoch": 0.334851326011251,
      "grad_norm": 1.0537647008895874,
      "learning_rate": 4.442658092175777e-05,
      "loss": 0.3355,
      "step": 625
    },
    {
      "epoch": 0.34824537905170105,
      "grad_norm": 1.1164579391479492,
      "learning_rate": 4.420328688817435e-05,
      "loss": 0.3266,
      "step": 650
    },
    {
      "epoch": 0.3616394320921511,
      "grad_norm": 1.0582681894302368,
      "learning_rate": 4.397999285459093e-05,
      "loss": 0.3176,
      "step": 675
    },
    {
      "epoch": 0.37503348513260115,
      "grad_norm": 0.8431617021560669,
      "learning_rate": 4.37566988210075e-05,
      "loss": 0.3157,
      "step": 700
    },
    {
      "epoch": 0.38842753817305115,
      "grad_norm": 1.1432774066925049,
      "learning_rate": 4.3533404787424084e-05,
      "loss": 0.3207,
      "step": 725
    },
    {
      "epoch": 0.4018215912135012,
      "grad_norm": 0.976091742515564,
      "learning_rate": 4.331011075384066e-05,
      "loss": 0.3225,
      "step": 750
    },
    {
      "epoch": 0.41521564425395124,
      "grad_norm": 1.0849816799163818,
      "learning_rate": 4.308681672025724e-05,
      "loss": 0.3097,
      "step": 775
    },
    {
      "epoch": 0.4286096972944013,
      "grad_norm": 0.7388479709625244,
      "learning_rate": 4.2863522686673816e-05,
      "loss": 0.3111,
      "step": 800
    },
    {
      "epoch": 0.44200375033485134,
      "grad_norm": 0.940429151058197,
      "learning_rate": 4.264022865309039e-05,
      "loss": 0.2963,
      "step": 825
    },
    {
      "epoch": 0.4553978033753014,
      "grad_norm": 0.9493727087974548,
      "learning_rate": 4.241693461950697e-05,
      "loss": 0.2861,
      "step": 850
    },
    {
      "epoch": 0.4687918564157514,
      "grad_norm": 1.0036063194274902,
      "learning_rate": 4.219364058592355e-05,
      "loss": 0.3035,
      "step": 875
    },
    {
      "epoch": 0.48218590945620143,
      "grad_norm": 0.9269081950187683,
      "learning_rate": 4.197034655234012e-05,
      "loss": 0.3111,
      "step": 900
    },
    {
      "epoch": 0.4955799624966515,
      "grad_norm": 0.8546565771102905,
      "learning_rate": 4.17470525187567e-05,
      "loss": 0.2973,
      "step": 925
    },
    {
      "epoch": 0.5089740155371015,
      "grad_norm": 1.0723605155944824,
      "learning_rate": 4.152375848517328e-05,
      "loss": 0.2851,
      "step": 950
    },
    {
      "epoch": 0.5223680685775516,
      "grad_norm": 0.9260022044181824,
      "learning_rate": 4.130046445158985e-05,
      "loss": 0.2861,
      "step": 975
    },
    {
      "epoch": 0.5357621216180016,
      "grad_norm": 0.840735673904419,
      "learning_rate": 4.1077170418006434e-05,
      "loss": 0.3037,
      "step": 1000
    },
    {
      "epoch": 0.5491561746584517,
      "grad_norm": 0.9994663000106812,
      "learning_rate": 4.085387638442301e-05,
      "loss": 0.2869,
      "step": 1025
    },
    {
      "epoch": 0.5625502276989017,
      "grad_norm": 0.9432574510574341,
      "learning_rate": 4.0630582350839584e-05,
      "loss": 0.294,
      "step": 1050
    },
    {
      "epoch": 0.5759442807393518,
      "grad_norm": 0.8182719945907593,
      "learning_rate": 4.0407288317256166e-05,
      "loss": 0.2738,
      "step": 1075
    },
    {
      "epoch": 0.5893383337798017,
      "grad_norm": 0.9875134825706482,
      "learning_rate": 4.018399428367274e-05,
      "loss": 0.2887,
      "step": 1100
    },
    {
      "epoch": 0.6027323868202518,
      "grad_norm": 0.9147534370422363,
      "learning_rate": 3.9960700250089315e-05,
      "loss": 0.2963,
      "step": 1125
    },
    {
      "epoch": 0.6161264398607018,
      "grad_norm": 1.1223948001861572,
      "learning_rate": 3.97374062165059e-05,
      "loss": 0.2849,
      "step": 1150
    },
    {
      "epoch": 0.6295204929011519,
      "grad_norm": 0.9061877727508545,
      "learning_rate": 3.951411218292247e-05,
      "loss": 0.2728,
      "step": 1175
    },
    {
      "epoch": 0.6429145459416019,
      "grad_norm": 1.0950931310653687,
      "learning_rate": 3.929081814933905e-05,
      "loss": 0.2778,
      "step": 1200
    },
    {
      "epoch": 0.656308598982052,
      "grad_norm": 1.1293002367019653,
      "learning_rate": 3.906752411575563e-05,
      "loss": 0.2745,
      "step": 1225
    },
    {
      "epoch": 0.669702652022502,
      "grad_norm": 0.9998095631599426,
      "learning_rate": 3.88442300821722e-05,
      "loss": 0.2782,
      "step": 1250
    },
    {
      "epoch": 0.6830967050629521,
      "grad_norm": 0.9303356409072876,
      "learning_rate": 3.8620936048588785e-05,
      "loss": 0.2718,
      "step": 1275
    },
    {
      "epoch": 0.6964907581034021,
      "grad_norm": 0.9688259959220886,
      "learning_rate": 3.839764201500536e-05,
      "loss": 0.2765,
      "step": 1300
    },
    {
      "epoch": 0.7098848111438522,
      "grad_norm": 1.1353448629379272,
      "learning_rate": 3.8174347981421934e-05,
      "loss": 0.2605,
      "step": 1325
    },
    {
      "epoch": 0.7232788641843022,
      "grad_norm": 1.2511919736862183,
      "learning_rate": 3.7951053947838516e-05,
      "loss": 0.2676,
      "step": 1350
    },
    {
      "epoch": 0.7366729172247523,
      "grad_norm": 1.1914199590682983,
      "learning_rate": 3.77277599142551e-05,
      "loss": 0.2623,
      "step": 1375
    },
    {
      "epoch": 0.7500669702652023,
      "grad_norm": 0.9698443412780762,
      "learning_rate": 3.7504465880671665e-05,
      "loss": 0.2596,
      "step": 1400
    },
    {
      "epoch": 0.7634610233056522,
      "grad_norm": 1.2940926551818848,
      "learning_rate": 3.728117184708825e-05,
      "loss": 0.2669,
      "step": 1425
    },
    {
      "epoch": 0.7768550763461023,
      "grad_norm": 0.9568777680397034,
      "learning_rate": 3.705787781350483e-05,
      "loss": 0.2649,
      "step": 1450
    },
    {
      "epoch": 0.7902491293865523,
      "grad_norm": 1.110059380531311,
      "learning_rate": 3.68345837799214e-05,
      "loss": 0.2534,
      "step": 1475
    },
    {
      "epoch": 0.8036431824270024,
      "grad_norm": 1.2022334337234497,
      "learning_rate": 3.661128974633798e-05,
      "loss": 0.2578,
      "step": 1500
    },
    {
      "epoch": 0.8170372354674524,
      "grad_norm": 0.9775505661964417,
      "learning_rate": 3.638799571275456e-05,
      "loss": 0.2642,
      "step": 1525
    },
    {
      "epoch": 0.8304312885079025,
      "grad_norm": 1.0487926006317139,
      "learning_rate": 3.6164701679171135e-05,
      "loss": 0.2632,
      "step": 1550
    },
    {
      "epoch": 0.8438253415483525,
      "grad_norm": 1.1899590492248535,
      "learning_rate": 3.594140764558771e-05,
      "loss": 0.2785,
      "step": 1575
    },
    {
      "epoch": 0.8572193945888026,
      "grad_norm": 1.1265990734100342,
      "learning_rate": 3.571811361200429e-05,
      "loss": 0.2662,
      "step": 1600
    },
    {
      "epoch": 0.8706134476292526,
      "grad_norm": 1.0818371772766113,
      "learning_rate": 3.5494819578420866e-05,
      "loss": 0.2591,
      "step": 1625
    },
    {
      "epoch": 0.8840075006697027,
      "grad_norm": 1.0069172382354736,
      "learning_rate": 3.527152554483744e-05,
      "loss": 0.2543,
      "step": 1650
    },
    {
      "epoch": 0.8974015537101527,
      "grad_norm": 1.0341870784759521,
      "learning_rate": 3.504823151125402e-05,
      "loss": 0.2692,
      "step": 1675
    },
    {
      "epoch": 0.9107956067506028,
      "grad_norm": 1.3508957624435425,
      "learning_rate": 3.48249374776706e-05,
      "loss": 0.2548,
      "step": 1700
    },
    {
      "epoch": 0.9241896597910527,
      "grad_norm": 1.0272955894470215,
      "learning_rate": 3.460164344408718e-05,
      "loss": 0.2523,
      "step": 1725
    },
    {
      "epoch": 0.9375837128315028,
      "grad_norm": 1.1992541551589966,
      "learning_rate": 3.4378349410503754e-05,
      "loss": 0.2543,
      "step": 1750
    },
    {
      "epoch": 0.9509777658719528,
      "grad_norm": 1.1596901416778564,
      "learning_rate": 3.415505537692033e-05,
      "loss": 0.2523,
      "step": 1775
    },
    {
      "epoch": 0.9643718189124029,
      "grad_norm": 1.0910412073135376,
      "learning_rate": 3.393176134333691e-05,
      "loss": 0.2479,
      "step": 1800
    },
    {
      "epoch": 0.9777658719528529,
      "grad_norm": 0.9226016998291016,
      "learning_rate": 3.3708467309753485e-05,
      "loss": 0.2466,
      "step": 1825
    },
    {
      "epoch": 0.991159924993303,
      "grad_norm": 0.899502694606781,
      "learning_rate": 3.348517327617006e-05,
      "loss": 0.247,
      "step": 1850
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2487439066171646,
      "eval_runtime": 542.4472,
      "eval_samples_per_second": 6.664,
      "eval_steps_per_second": 3.333,
      "step": 1867
    },
    {
      "epoch": 1.004286096972944,
      "grad_norm": 1.2377009391784668,
      "learning_rate": 3.326187924258664e-05,
      "loss": 0.2371,
      "step": 1875
    },
    {
      "epoch": 1.017680150013394,
      "grad_norm": 1.2344993352890015,
      "learning_rate": 3.3038585209003216e-05,
      "loss": 0.2439,
      "step": 1900
    },
    {
      "epoch": 1.031074203053844,
      "grad_norm": 1.0868570804595947,
      "learning_rate": 3.281529117541979e-05,
      "loss": 0.2552,
      "step": 1925
    },
    {
      "epoch": 1.0444682560942942,
      "grad_norm": 1.0302329063415527,
      "learning_rate": 3.259199714183637e-05,
      "loss": 0.2525,
      "step": 1950
    },
    {
      "epoch": 1.057862309134744,
      "grad_norm": 1.0213332176208496,
      "learning_rate": 3.2368703108252954e-05,
      "loss": 0.2456,
      "step": 1975
    },
    {
      "epoch": 1.0712563621751943,
      "grad_norm": 1.110936164855957,
      "learning_rate": 3.214540907466952e-05,
      "loss": 0.2417,
      "step": 2000
    },
    {
      "epoch": 1.0846504152156442,
      "grad_norm": 1.513890266418457,
      "learning_rate": 3.1922115041086104e-05,
      "loss": 0.2518,
      "step": 2025
    },
    {
      "epoch": 1.0980444682560944,
      "grad_norm": 1.2329691648483276,
      "learning_rate": 3.1698821007502685e-05,
      "loss": 0.2378,
      "step": 2050
    },
    {
      "epoch": 1.1114385212965443,
      "grad_norm": 1.3371831178665161,
      "learning_rate": 3.1475526973919253e-05,
      "loss": 0.2413,
      "step": 2075
    },
    {
      "epoch": 1.1248325743369945,
      "grad_norm": 1.22776198387146,
      "learning_rate": 3.1252232940335835e-05,
      "loss": 0.2363,
      "step": 2100
    },
    {
      "epoch": 1.1382266273774444,
      "grad_norm": 1.19737708568573,
      "learning_rate": 3.102893890675242e-05,
      "loss": 0.2517,
      "step": 2125
    },
    {
      "epoch": 1.1516206804178943,
      "grad_norm": 1.0417191982269287,
      "learning_rate": 3.080564487316899e-05,
      "loss": 0.2353,
      "step": 2150
    },
    {
      "epoch": 1.1650147334583445,
      "grad_norm": 1.3024839162826538,
      "learning_rate": 3.0582350839585566e-05,
      "loss": 0.2373,
      "step": 2175
    },
    {
      "epoch": 1.1784087864987947,
      "grad_norm": 1.3223782777786255,
      "learning_rate": 3.0359056806002144e-05,
      "loss": 0.2268,
      "step": 2200
    },
    {
      "epoch": 1.1918028395392446,
      "grad_norm": 1.1192681789398193,
      "learning_rate": 3.0135762772418723e-05,
      "loss": 0.2444,
      "step": 2225
    },
    {
      "epoch": 1.2051968925796945,
      "grad_norm": 1.0768851041793823,
      "learning_rate": 2.9912468738835298e-05,
      "loss": 0.2375,
      "step": 2250
    },
    {
      "epoch": 1.2185909456201447,
      "grad_norm": 0.9196657538414001,
      "learning_rate": 2.9689174705251876e-05,
      "loss": 0.2384,
      "step": 2275
    },
    {
      "epoch": 1.2319849986605946,
      "grad_norm": 1.0091681480407715,
      "learning_rate": 2.9465880671668454e-05,
      "loss": 0.2282,
      "step": 2300
    },
    {
      "epoch": 1.2453790517010448,
      "grad_norm": 1.1303961277008057,
      "learning_rate": 2.9242586638085036e-05,
      "loss": 0.2395,
      "step": 2325
    },
    {
      "epoch": 1.2587731047414947,
      "grad_norm": 0.9139474034309387,
      "learning_rate": 2.9019292604501607e-05,
      "loss": 0.2331,
      "step": 2350
    },
    {
      "epoch": 1.272167157781945,
      "grad_norm": 1.275022029876709,
      "learning_rate": 2.8795998570918185e-05,
      "loss": 0.2383,
      "step": 2375
    },
    {
      "epoch": 1.2855612108223948,
      "grad_norm": 1.069022536277771,
      "learning_rate": 2.8572704537334767e-05,
      "loss": 0.2364,
      "step": 2400
    },
    {
      "epoch": 1.2989552638628448,
      "grad_norm": 1.4072537422180176,
      "learning_rate": 2.8349410503751338e-05,
      "loss": 0.2419,
      "step": 2425
    },
    {
      "epoch": 1.312349316903295,
      "grad_norm": 1.2466908693313599,
      "learning_rate": 2.8126116470167916e-05,
      "loss": 0.2373,
      "step": 2450
    },
    {
      "epoch": 1.325743369943745,
      "grad_norm": 1.2102952003479004,
      "learning_rate": 2.7902822436584498e-05,
      "loss": 0.2283,
      "step": 2475
    },
    {
      "epoch": 1.339137422984195,
      "grad_norm": 0.9115263223648071,
      "learning_rate": 2.767952840300107e-05,
      "loss": 0.2335,
      "step": 2500
    },
    {
      "epoch": 1.352531476024645,
      "grad_norm": 1.059287428855896,
      "learning_rate": 2.745623436941765e-05,
      "loss": 0.2325,
      "step": 2525
    },
    {
      "epoch": 1.3659255290650951,
      "grad_norm": 1.1313194036483765,
      "learning_rate": 2.723294033583423e-05,
      "loss": 0.2279,
      "step": 2550
    },
    {
      "epoch": 1.379319582105545,
      "grad_norm": 1.0025566816329956,
      "learning_rate": 2.7009646302250807e-05,
      "loss": 0.2294,
      "step": 2575
    },
    {
      "epoch": 1.3927136351459952,
      "grad_norm": 1.240206241607666,
      "learning_rate": 2.6786352268667382e-05,
      "loss": 0.2237,
      "step": 2600
    },
    {
      "epoch": 1.4061076881864452,
      "grad_norm": 1.3601422309875488,
      "learning_rate": 2.656305823508396e-05,
      "loss": 0.2321,
      "step": 2625
    },
    {
      "epoch": 1.4195017412268953,
      "grad_norm": 1.2357484102249146,
      "learning_rate": 2.633976420150054e-05,
      "loss": 0.2269,
      "step": 2650
    },
    {
      "epoch": 1.4328957942673453,
      "grad_norm": 0.9886751174926758,
      "learning_rate": 2.6116470167917114e-05,
      "loss": 0.2242,
      "step": 2675
    },
    {
      "epoch": 1.4462898473077954,
      "grad_norm": 1.1216487884521484,
      "learning_rate": 2.5893176134333692e-05,
      "loss": 0.2267,
      "step": 2700
    },
    {
      "epoch": 1.4596839003482454,
      "grad_norm": 1.1151882410049438,
      "learning_rate": 2.566988210075027e-05,
      "loss": 0.2276,
      "step": 2725
    },
    {
      "epoch": 1.4730779533886955,
      "grad_norm": 1.1324933767318726,
      "learning_rate": 2.5446588067166848e-05,
      "loss": 0.2362,
      "step": 2750
    },
    {
      "epoch": 1.4864720064291455,
      "grad_norm": 1.435706377029419,
      "learning_rate": 2.5223294033583423e-05,
      "loss": 0.2328,
      "step": 2775
    },
    {
      "epoch": 1.4998660594695954,
      "grad_norm": 1.1575936079025269,
      "learning_rate": 2.5e-05,
      "loss": 0.2321,
      "step": 2800
    },
    {
      "epoch": 1.5132601125100456,
      "grad_norm": 1.260124921798706,
      "learning_rate": 2.4776705966416576e-05,
      "loss": 0.2159,
      "step": 2825
    },
    {
      "epoch": 1.5266541655504957,
      "grad_norm": 1.1975829601287842,
      "learning_rate": 2.4553411932833158e-05,
      "loss": 0.2321,
      "step": 2850
    },
    {
      "epoch": 1.5400482185909457,
      "grad_norm": 1.0337003469467163,
      "learning_rate": 2.4330117899249732e-05,
      "loss": 0.2269,
      "step": 2875
    },
    {
      "epoch": 1.5534422716313956,
      "grad_norm": 1.186119556427002,
      "learning_rate": 2.410682386566631e-05,
      "loss": 0.2162,
      "step": 2900
    },
    {
      "epoch": 1.5668363246718457,
      "grad_norm": 1.0957468748092651,
      "learning_rate": 2.388352983208289e-05,
      "loss": 0.2357,
      "step": 2925
    },
    {
      "epoch": 1.5802303777122957,
      "grad_norm": 1.3561487197875977,
      "learning_rate": 2.3660235798499467e-05,
      "loss": 0.2334,
      "step": 2950
    },
    {
      "epoch": 1.5936244307527456,
      "grad_norm": 1.2551062107086182,
      "learning_rate": 2.3436941764916042e-05,
      "loss": 0.2331,
      "step": 2975
    },
    {
      "epoch": 1.6070184837931958,
      "grad_norm": 1.3376507759094238,
      "learning_rate": 2.321364773133262e-05,
      "loss": 0.2153,
      "step": 3000
    },
    {
      "epoch": 1.620412536833646,
      "grad_norm": 1.1167677640914917,
      "learning_rate": 2.29903536977492e-05,
      "loss": 0.2162,
      "step": 3025
    },
    {
      "epoch": 1.6338065898740959,
      "grad_norm": 1.1372807025909424,
      "learning_rate": 2.2767059664165773e-05,
      "loss": 0.2212,
      "step": 3050
    },
    {
      "epoch": 1.6472006429145458,
      "grad_norm": 1.2696982622146606,
      "learning_rate": 2.254376563058235e-05,
      "loss": 0.2269,
      "step": 3075
    },
    {
      "epoch": 1.660594695954996,
      "grad_norm": 1.4194999933242798,
      "learning_rate": 2.232047159699893e-05,
      "loss": 0.226,
      "step": 3100
    },
    {
      "epoch": 1.6739887489954461,
      "grad_norm": 1.1037184000015259,
      "learning_rate": 2.2097177563415504e-05,
      "loss": 0.2274,
      "step": 3125
    },
    {
      "epoch": 1.687382802035896,
      "grad_norm": 1.3236585855484009,
      "learning_rate": 2.1873883529832086e-05,
      "loss": 0.2394,
      "step": 3150
    },
    {
      "epoch": 1.700776855076346,
      "grad_norm": 1.161983847618103,
      "learning_rate": 2.165058949624866e-05,
      "loss": 0.2254,
      "step": 3175
    },
    {
      "epoch": 1.7141709081167962,
      "grad_norm": 1.1969871520996094,
      "learning_rate": 2.142729546266524e-05,
      "loss": 0.2225,
      "step": 3200
    },
    {
      "epoch": 1.7275649611572463,
      "grad_norm": 1.0383784770965576,
      "learning_rate": 2.1204001429081817e-05,
      "loss": 0.2199,
      "step": 3225
    },
    {
      "epoch": 1.7409590141976963,
      "grad_norm": 1.4159401655197144,
      "learning_rate": 2.0980707395498395e-05,
      "loss": 0.218,
      "step": 3250
    },
    {
      "epoch": 1.7543530672381462,
      "grad_norm": 1.0732771158218384,
      "learning_rate": 2.075741336191497e-05,
      "loss": 0.2056,
      "step": 3275
    },
    {
      "epoch": 1.7677471202785964,
      "grad_norm": 1.3883687257766724,
      "learning_rate": 2.053411932833155e-05,
      "loss": 0.2182,
      "step": 3300
    },
    {
      "epoch": 1.7811411733190463,
      "grad_norm": 1.1519609689712524,
      "learning_rate": 2.0310825294748127e-05,
      "loss": 0.2149,
      "step": 3325
    },
    {
      "epoch": 1.7945352263594962,
      "grad_norm": 1.7636600732803345,
      "learning_rate": 2.00875312611647e-05,
      "loss": 0.2321,
      "step": 3350
    },
    {
      "epoch": 1.8079292793999464,
      "grad_norm": 1.1120376586914062,
      "learning_rate": 1.986423722758128e-05,
      "loss": 0.2207,
      "step": 3375
    },
    {
      "epoch": 1.8213233324403966,
      "grad_norm": 1.4772430658340454,
      "learning_rate": 1.9640943193997858e-05,
      "loss": 0.215,
      "step": 3400
    },
    {
      "epoch": 1.8347173854808465,
      "grad_norm": 0.9496152997016907,
      "learning_rate": 1.9417649160414433e-05,
      "loss": 0.2217,
      "step": 3425
    },
    {
      "epoch": 1.8481114385212964,
      "grad_norm": 1.371234655380249,
      "learning_rate": 1.919435512683101e-05,
      "loss": 0.2195,
      "step": 3450
    },
    {
      "epoch": 1.8615054915617466,
      "grad_norm": 1.4210509061813354,
      "learning_rate": 1.897106109324759e-05,
      "loss": 0.2197,
      "step": 3475
    },
    {
      "epoch": 1.8748995446021968,
      "grad_norm": 1.254129409790039,
      "learning_rate": 1.8747767059664167e-05,
      "loss": 0.2215,
      "step": 3500
    },
    {
      "epoch": 1.8882935976426467,
      "grad_norm": 1.43967866897583,
      "learning_rate": 1.8524473026080742e-05,
      "loss": 0.222,
      "step": 3525
    },
    {
      "epoch": 1.9016876506830966,
      "grad_norm": 1.3729357719421387,
      "learning_rate": 1.8301178992497324e-05,
      "loss": 0.2131,
      "step": 3550
    },
    {
      "epoch": 1.9150817037235468,
      "grad_norm": 1.0119004249572754,
      "learning_rate": 1.80778849589139e-05,
      "loss": 0.2276,
      "step": 3575
    },
    {
      "epoch": 1.9284757567639967,
      "grad_norm": 1.0804041624069214,
      "learning_rate": 1.7854590925330473e-05,
      "loss": 0.2262,
      "step": 3600
    },
    {
      "epoch": 1.9418698098044467,
      "grad_norm": 1.0993715524673462,
      "learning_rate": 1.7631296891747055e-05,
      "loss": 0.2249,
      "step": 3625
    },
    {
      "epoch": 1.9552638628448968,
      "grad_norm": 1.1117987632751465,
      "learning_rate": 1.740800285816363e-05,
      "loss": 0.2082,
      "step": 3650
    },
    {
      "epoch": 1.968657915885347,
      "grad_norm": 1.263724684715271,
      "learning_rate": 1.7184708824580208e-05,
      "loss": 0.2226,
      "step": 3675
    },
    {
      "epoch": 1.982051968925797,
      "grad_norm": 1.0703328847885132,
      "learning_rate": 1.6961414790996786e-05,
      "loss": 0.2189,
      "step": 3700
    },
    {
      "epoch": 1.9954460219662469,
      "grad_norm": 1.1737295389175415,
      "learning_rate": 1.673812075741336e-05,
      "loss": 0.2262,
      "step": 3725
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2174070030450821,
      "eval_runtime": 542.3806,
      "eval_samples_per_second": 6.665,
      "eval_steps_per_second": 3.333,
      "step": 3734
    }
  ],
  "logging_steps": 25,
  "max_steps": 5598,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2131261689500795e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
